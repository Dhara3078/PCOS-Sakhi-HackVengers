# -*- coding: utf-8 -*-

"""PCOS-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_pNpXAtQEW5qS6iXgRHeMUwpTiftHSaK

# **PCOS prediction**

### import libraries
"""

# import tensorflowjs as tfjs
import sys
import json
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
# from google.colab import drive
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

"""### mounted google drive"""

# drive.mount('/content/drive')

# loading two datasets
PCOS_woinf = pd.read_excel(
    "PCOS_data_without_infertility (1).xlsx")
PCOS_inf = pd.read_csv(
    "PCOS_infertility.csv")

data = pd.merge(PCOS_woinf, PCOS_inf, on='Patient File No.',
                suffixes={'', '_y'}, how='left')

# Dropping the repeated features after merging
data = data.drop(['Unnamed: 41', 'Sl. No_y', 'PCOS (Y/N)_y', '  I   beta-HCG(mIU/mL)_y',
                  'II    beta-HCG(mIU/mL)_y', 'AMH(ng/mL)_y', 'Patient File No.', 'Sl. No', '  I   beta-HCG(mIU/mL)',
                  'II    beta-HCG(mIU/mL)', 'AMH(ng/mL)', 'TSH (mIU/L)', 'PRL(ng/mL)', 'Vit D3 (ng/mL)', 'PRG(ng/mL)', 'RBS(mg/dl)', 'Follicle No. (L)', 'Follicle No. (R)', 'Endometrium (mm)', 'Hb(g/dl)', 'Avg. F size (L) (mm)', 'Avg. F size (R) (mm)', 'RR (breaths/min)', 'BP _Systolic (mmHg)', 'BP _Diastolic (mmHg)'], axis=1)

# Taking a look at the dataset
data.head()
data['Waist:Hip Ratio']


data = data.fillna(0)
data.isnull().sum()

# data = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/pcos.csv")

# data.head(10)

# data.shape

"""### info of dataset

"""

# data.info()

# data.isnull().sum()  # checking for null values

# data.describe()  # statistical data for each numerical column

# Examaning a correlation matrix of all the features

corrmat = data.corr()
plt.subplots(figsize=(18, 18))
sns.heatmap(corrmat, cmap="Pastel1", square=True)

corrmat["PCOS (Y/N)"].sort_values(ascending=False)

# Having a look at features bearing significant correlation

plt.figure(figsize=(12, 12))
k = 12  # number of variables with positive for heatmap
l = 3  # number of variables with negative for heatmap
cols_p = corrmat.nlargest(k, "PCOS (Y/N)")["PCOS (Y/N)"].index
cols_n = corrmat.nsmallest(l, "PCOS (Y/N)")["PCOS (Y/N)"].index
cols = cols_p.append(cols_n)

cm = np.corrcoef(data[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True, cmap="Pastel1", annot=True, square=True, fmt='.2f', annot_kws={
                 'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

# Length of menstrual phase in PCOS vs normal
color = ["teal", "plum"]
fig = sns.lmplot(data=data, x=" Age (yrs)", y="Cycle length(days)",
                 hue="PCOS (Y/N)", palette=color)
# plt.show(fig)

# Pattern of weight gain (BMI) over years in PCOS and Normal.
fig = sns.lmplot(data=data, x=" Age (yrs)", y="BMI",
                 hue="PCOS (Y/N)", palette=color)
# plt.show(fig)

# cycle IR wrt age
# sns.lmplot(data=data, x=" Age (yrs)", y="Cycle(months)",
#            hue="PCOS (Y/N)", palette=color)
plt.show()

# Distribution of follicles in both ovaries.
# sns.lmplot(data =data,x='Follicle No. (R)',y='Follicle No. (L)', hue="PCOS (Y/N)",palette=color)
# plt.show()

"""### dropping the unecessary columns"""

# data.drop(columns=["Sl No", "Patient File No"], axis=1, inplace=True)
#  adding inplace = true drops the columns from original dataframe,and if not used, it creates a new dataframe

data.columns

"""### splitting numerical and categorical columns

"""

numerical_cols = ["No. of aborptions", "Weight (Kg)", "Height(Cm) ", "BMI", "Blood Group", "Pulse rate(bpm) ",
                  "Cycle length(days)", "Marraige Status (Yrs)", "Hip(inch)", "Waist(inch)", "Waist:Hip Ratio"]
categorical_cols = list(
    set(data.columns) - set(numerical_cols) - {"PCOS (Y/N)"})

numerical_cols

categorical_cols

"""### splitting data"""

data_train, data_test = train_test_split(data, test_size=0.5, random_state=42)

# for merged dataset
merge_train, merge_test = train_test_split(
    data, test_size=0.3, random_state=42)

merge_test.columns

"""### scaling numerical columns
this is required because the numerical columns might have data 1 as well as 800. in this case 800 may be considered as outlier. so we need to apply standard scaling to bring all the values in a particular range 
"""

scaler = StandardScaler()


def get_features_and_target_array(data, numerical_cols, categorical_cols, scaler):
    # it will take every data point of numerical column and it will transform it to -1 to 1 range
    x_numeric_scaled = scaler.fit_transform(data[numerical_cols])
    x_categorical = data[categorical_cols].to_numpy()  # categorical cols
    # single array of the above two arrays so that it can directly be added to model
    x = np.hstack((x_categorical, x_numeric_scaled))
    y = data["PCOS (Y/N)"]
    return x, y


x_train, y_train = get_features_and_target_array(
    data_train, numerical_cols, categorical_cols, scaler)

# without scaling

x_test = data_test.drop(columns=["PCOS (Y/N)"])
y_test = data_test['PCOS (Y/N)']
x_train = data_train.drop(columns=["PCOS (Y/N)"])
y_train = data_train['PCOS (Y/N)']

# for merged dataset
mx_test = merge_test.drop(columns=["PCOS (Y/N)"])
my_test = merge_test['PCOS (Y/N)']
mx_train = merge_train.drop(columns=["PCOS (Y/N)"])
my_train = merge_train['PCOS (Y/N)']


# with scaling
xs_train, ys_train = get_features_and_target_array(
    data_train, numerical_cols, categorical_cols, scaler)
xs_test, ys_test = get_features_and_target_array(
    data_test, numerical_cols, categorical_cols, scaler)

y_train

"""### train
# 1. Logistic Regression
"""

# clf = LogisticRegression(solver='lbfgs', max_iter=1000)
# clf.fit(mx_train, my_train)


# # x_test, y_test = get_features_and_target_array(data_test, numerical_cols, categorical_cols, scaler)

# test_pred = clf.predict(mx_test)

# mean_squared_error(my_test, test_pred)

# accuracy_score(my_test, test_pred)

# confusion_matrix(my_test, test_pred)

# data.head()

# """# 2. Decision Tree"""

# dc_clf = DecisionTreeClassifier()
# dc_clf.fit(mx_train, my_train)

# dlf_pred = dc_clf.predict(mx_test)
# print(mean_squared_error(my_test, dlf_pred))
# print(accuracy_score(my_test, dlf_pred))

# """# 3. SVM

# """

# svm_clf = SVC()
# svm_clf.fit(mx_train, my_train)

# svm_pred = svm_clf.predict(mx_test)
# print(mean_squared_error(my_test, svm_pred))
# print(accuracy_score(my_test, svm_pred))

# random forest

rfc = RandomForestClassifier()
rfc.fit(mx_train, my_train)
pred_rfc = rfc.predict(mx_test)
accuracy = accuracy_score(my_test, pred_rfc)
# print(pred_rfc)
excel_path = sys.argv[1]
data = pd.read_excel(excel_path)
ans = rfc.predict(data)
if (ans == 1):
    print("You need to consult a doctor!")
else:
    print("You are happy and healthy and appear PCOS free!")
